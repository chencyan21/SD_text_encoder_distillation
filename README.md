# Stable Diffusion 文本编码器蒸馏

**作者**：CTR  
**课程**：自然语言处理  
**Huggingface**：[Huggingface](https://huggingface.co/CyanCCT/DistillatedTextEncoderInSD)


## 项目描述

本项目通过知识蒸馏技术优化 Stable Diffusion 的文本编码器，使其在资源受限的环境中高效运行。Stable Diffusion 是一个强大的文本到图像扩散模型，但其基于 CLIP 的文本编码器参数量大（340 百万），计算需求高，限制了其在移动设备或边缘计算场景中的应用。本项目通过知识蒸馏，将大型文本编码器（教师模型）的知识转移到一个更小的学生模型中，降低计算需求，同时保持较高的性能。

## 背景与动机

Stable Diffusion 由变分自编码器（VAE）、U-Net 和 CLIP 文本编码器组成，能够生成高质量、语义一致的图像。然而，CLIP 文本编码器的复杂性使其难以在资源受限环境中实时运行。知识蒸馏是一种有效的模型压缩技术，通过将大型模型的知识转移到小型模型，平衡性能与效率。本项目旨在验证知识蒸馏在 Stable Diffusion 文本编码器优化中的应用潜力。

## 方法论

本项目设计并训练了一个 12 层 Transformer 架构的学生模型，具体方法包括：

- **模型架构**：学生模型从头训练，包含 12 层 Transformer，参数量为 151 百万。
- **损失函数**：采用均方误差（MSE）损失函数，衡量学生模型与教师模型输出之间的差异。
- **对齐策略**：使用中间层隐藏状态对齐，确保学生模型学习到教师模型的语义表示。
- **分词器**：学生模型与教师模型共享相同的分词器，保证文本处理一致性。
- **数据集**：在 COCO 数据集上进行训练和验证，仅使用文本数据（图像标题）。
- **训练环境**：使用 Stable Diffusion V2.1（CLIP-ViT-L-336px 作为教师模型），在 4090D GPU 上训练 40 个 epoch，批大小为 256。

## 实验结果

实验结果表明，学生模型在效率和性能上均取得了显著成果：

- **模型效率**：
  - 参数量：学生模型 151 百万，教师模型 340 百万，减少约 56%。
  - 推理速度：平均推理时间从 2.60 秒/图像降至 2.54 秒/图像，提升 2%-3%。
- **性能指标**：
  - CLIP-I 分数：学生模型 65.5，教师模型 72.1（略低）。
  - CLIP-T 分数：学生模型 15.1，教师模型 14.7（略高，表明更好的文本语义对齐）。
  - DINO 分数：学生模型 38.7，教师模型 48.4（略低）。
- **定性评估**：学生模型生成的图像与文本提示高度一致，尽管在细节上略逊于教师模型。

以下表格总结了性能对比：

| 指标               | 学生模型 | 教师模型 |
| ------------------ | -------- | -------- |
| 参数量 (百万)      | 151      | 340      |
| 推理时间 (秒/图像) | 2.54     | 2.60     |
| CLIP-I 分数        | 65.5     | 72.1     |
| CLIP-T 分数        | 15.1     | 14.7     |
| DINO 分数          | 38.7     | 48.4     |

## 结论与未来工作

本研究验证了知识蒸馏在压缩 Stable Diffusion 文本编码器方面的有效性，学生模型在显著降低资源需求的同时，保持了与教师模型相近的性能。这为在资源受限环境中部署 Stable Diffusion 提供了实用解决方案。未来工作方向包括：

- 增强内容过滤机制，提升生成内容的质量和安全性。
- 进一步压缩模型，探索更轻量化的架构。
- 扩展知识蒸馏方法到其他多模态生成任务，如视频生成和 3D 建模。


## 参考文献

- Stable Diffusion V2.1 模型，Huggingface。
- COCO 数据集，Microsoft。